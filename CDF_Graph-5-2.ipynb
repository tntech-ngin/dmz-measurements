{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559684f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from ripe.atlas.cousteau import (\n",
    "    AtlasResultsRequest\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "!pip3 install jc\n",
    "\n",
    "import jc #for traceroute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None #make sure all columns are displayed\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98207f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ping RTT (Leo Data) - single measurement\n",
    "with open('pingTest9-17pmOct200.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "rtt = []\n",
    "for x, row in df1.iterrows():\n",
    "    df1['icmp_replies'][x] = pd.json_normalize(df1['icmp_replies'][x])\n",
    "    for result in df1['icmp_replies'][x]:\n",
    "        rtt.append(df1['icmp_replies'][x]['time'])\n",
    "\n",
    "data = np.array(rtt)\n",
    "count, bins_count = np.histogram(data, bins=300)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, label=\"Ping RTT CDF\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title('Ping RTT')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('RTT(in milliseconds)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcdc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ping RTT (PerfSONAR) - single measurement \n",
    "\n",
    "with open('example2.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "d1 = data[\"val\"]                                #section off values section of aggregation file\n",
    "d1 = {float(k):v for (k,v) in d1.items()}       #convert keys to floats\n",
    "d1 = dict(sorted(d1.items()))                   #sort d1 by keys (rtt)\n",
    "\n",
    "xAxis = [key for key, value in d1.items()]      #rtt\n",
    "yAxis = [value for key, value in d1.items()]    #occurences\n",
    "plt.grid(True)\n",
    "plt.plot(xAxis,yAxis, color='maroon', marker='o')\n",
    "plt.xlabel('rtt')\n",
    "plt.ylabel('occurences')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "count = np.array(yAxis)\n",
    "bins_count = np.array(xAxis)\n",
    "\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "plt.plot(bins_count[0:], cdf, label=\"Ping RTT CDF\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title('Ping RTT ' + data[\"ip\"])\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('RTT(in milliseconds)')\n",
    "plt.grid()\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db1278",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Ping RTT CDF (RIPE ATLAS)\n",
    "kwargs = {\n",
    "    \"msm_id\": 38331308\n",
    "}\n",
    "\n",
    "is_success, results = AtlasResultsRequest(**kwargs).create()\n",
    "\n",
    "if is_success:\n",
    "    #print the json string\n",
    "    #print(results)\n",
    "\n",
    "    #df1 = pd.json_normalize(results)\n",
    "    #display(df1)\n",
    "    \n",
    "    \n",
    "    #for x, row in df1.iterrows():\n",
    "        #df1['result'][x] = pd.json_normalize(df1['result'][x])\n",
    "\n",
    "    #CREATE DATA FRAME WITH COMPLETE MEASUREMENT RESULTS\n",
    "    df2 = pd.DataFrame(results)\n",
    "\n",
    "    #CREATE EMPTY LIST just_rtt THAT WILL CONTAIN RTT VALUES\n",
    "    just_rtt = []\n",
    "\n",
    "    #min_rtt = []\n",
    "    #max_rtt = []\n",
    "    #avg_rtt = []\n",
    "\n",
    "    #DISPLAY DF2 DATAFRAME\n",
    "    #display(df2)\n",
    "\n",
    "       \n",
    "    #FOR EACH ROW IN DF2\n",
    "    for x, row in df2.iterrows():\n",
    "\n",
    "        #NORMALIZING THE RESULTS \n",
    "        df2['result'][x] = pd.json_normalize(df2['result'][x])\n",
    "\n",
    "        #FOR EACH RESULT\n",
    "        for result in df2['result'][x]:\n",
    "\n",
    "            #IN THIS CASE (I AM NOT SURE IN THE CASE OF ALL MEASUREMENTS) THERE ARE THREE PACKETS SENT IN\n",
    "            # EACH INDIVIDUAL MEASUREMENT, SO THERE ARE THREE RTT VALUES TO BE COLLECTED IN EACH ROW.\n",
    "            #  THERE WERE KEY ERRORS WHEN APPENDING WITH A VARIABLE POSITION INDICATOR FOR THE RTT POSITION\n",
    "            #   SO THIS PROBLEM WAS RESOLVED BY HARDCODING THE RTT POSITION SINCE IT WOULD BE THE SAME FOR\n",
    "            #    EACH ROW\n",
    "\n",
    "            just_rtt.append(df2['result'][x][result][0])\n",
    "            \n",
    "            just_rtt.append(df2['result'][x][result][1])\n",
    "            \n",
    "            just_rtt.append(df2['result'][x][result][2])\n",
    "\n",
    "        #min_rtt.append(df2['min'])\n",
    "        #max_rtt.append(df2['max'])\n",
    "        #avg_rtt.append(df2['avg'])\n",
    "    \n",
    "#CREATE ARRAY WITH just_rtt LIST OF RTT VALUES\n",
    "data = np.array(just_rtt)\n",
    "\n",
    "#data1 = np.array(min_rtt)\n",
    "#data2 = np.array(max_rtt)\n",
    "#data3 = np.array(avg_rtt)\n",
    "\n",
    "#CREATE HISTOGRAM, BINS = 300 RESOLVED ISSUE OF GRAPH NOT BEGINNING AT 0 PERCENT ON Y-AXIS\n",
    "count, bins_count = np.histogram(data, bins=300)\n",
    "\n",
    "#count1, bins_count1 = np.histogram(data1, bins=300)\n",
    "#count2, bins_count2 = np.histogram(data2, bins=300)\n",
    "#count3, bins_count3 = np.histogram(data3, bins=300)\n",
    "\n",
    "#CALCULATE PDF, NEEDED FOR CALCULATION OF CDF\n",
    "pdf = count / sum(count)\n",
    "\n",
    "#pdf1 = count1 / sum(count1)\n",
    "#pdf2 = count2 / sum(count2)\n",
    "#pdf3 = count3 / sum(count3)\n",
    "\n",
    "#CALCULATE CDF\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "#cdf1 = np.cumsum(pdf1)\n",
    "#cdf2 = np.cumsum(pdf2)\n",
    "#cdf3 = np.cumsum(pdf3)\n",
    "\n",
    "#PLOT CDF\n",
    "plt.plot(bins_count[1:], cdf, label=\"Ping RTT CDF\")\n",
    "\n",
    "#plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "#plt.plot(bins_count1[1:], cdf1, label=\"Ping Min RTT CDF\")\n",
    "#plt.plot(bins_count2[1:], cdf2, label=\"Ping Max RTT CDF\")\n",
    "#plt.plot(bins_count3[1:], cdf3, label=\"Ping Avg RTT CDF\")\n",
    "#plt.axis([0,140,0,1.0])\n",
    "#SET Y-AXIS LIMIT FOR 0-1.0, THIS LEAVES THE X-AXIS FREE TO AUTOMATE RANGE AND ALLOWS FOR A MORE ACCURATE GRAPH\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Ping RTT')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('RTT(in milliseconds)')\n",
    "plt.grid()\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd141ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DON'T NEED THIS GRAPH B/C THERE IS NO PACKET LOSS\n",
    "\n",
    "#Ping Packet Loss CDF (RIPE ATLAS)\n",
    "kwargs = {\n",
    "    \"msm_id\": 38331308\n",
    "}\n",
    "\n",
    "is_success, results = AtlasResultsRequest(**kwargs).create()\n",
    "\n",
    "if is_success:\n",
    "    #print the json string\n",
    "    #print(results)\n",
    "\n",
    "    #df1 = pd.json_normalize(results)\n",
    "    #display(df1)\n",
    "    \n",
    "    \n",
    "    #for x, row in df1.iterrows():\n",
    "        #df1['result'][x] = pd.json_normalize(df1['result'][x])\n",
    "\n",
    "    #CREATE DATAFRAME WITH ENTIRETY OF MEASUREMENT RESULTS\n",
    "    df2 = pd.DataFrame(results)\n",
    "\n",
    "    #CREATE EMPTY LISTS sent AND received\n",
    "    sent = []\n",
    "    received = []\n",
    "\n",
    "    #print(df2[results])\n",
    "       \n",
    "    #FOR EACH ROW IN DF2\n",
    "    for x, row in df2.iterrows():\n",
    "        \n",
    "        #APPEND SENT AND RECEIVED VALUES TO THEIR DESIGNATED LISTS\n",
    "        sent.append(df2['sent'])\n",
    "        received.append(df2['rcvd'])\n",
    "\n",
    "#CREATE EMPTY LIST total_loss                \n",
    "total_loss = []\n",
    "\n",
    "#SUBTRACT RECEIVED VALUES FROM SENT VALUES TO FIND TOTAL LOSS, APPEND RESULT TO total_loss LIST\n",
    "zip_object = zip(sent, received)\n",
    "for sent, received in zip_object:\n",
    "    total_loss.append(sent-received)\n",
    "\n",
    "#SET DATA TO AN ARRAY MADE FROM total_loss LIST \n",
    "data = np.array(total_loss)\n",
    "\n",
    "#CREATE HISTOGRAM\n",
    "count, bins_count = np.histogram(data, bins=300)\n",
    "\n",
    "#CALCULATE PDF\n",
    "pdf = count / sum(count)\n",
    "\n",
    "#CALCULATE CDF\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "#plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "\n",
    "#PLOT CDF\n",
    "plt.plot(bins_count[1:], cdf, label=\"Ping Packet Loss CDF\")\n",
    "#plt.axis([0,50,0,1.0])\n",
    "\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Ping Packet Loss')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('Packet Loss')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057177c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MAKE THIS A BAR GRAPH\n",
    "#x axis - number of hops\n",
    "#y axis - average rtt and stdev across measurements \n",
    "\n",
    "#Traceroute RTT CDF (RIPE ATLAS)\n",
    "kwargs = {\n",
    "    \"msm_id\": 38384555\n",
    "}\n",
    "\n",
    "is_success, results = AtlasResultsRequest(**kwargs).create()\n",
    "\n",
    "if is_success:\n",
    "    #print the json string\n",
    "    #print(results)\n",
    "\n",
    "    traceroutes = pd.json_normalize(results)\n",
    "        #prototype path to an individual rtt\n",
    "    #    display(df1)\n",
    "    #    display(df1['result'][1][1]['result'][1]['rtt'])\n",
    "    #   df2 = df1['result'][1] #traceroute level\n",
    "    #    df2 = pd.json_normalize(df2) #hops level\n",
    "    #    df3 = df2['result'][1]\n",
    "    #    df3 = pd.json_normalize(df3) #1 hop level\n",
    "        #df2['rtt']\n",
    "    #    display(df3['rtt'])\n",
    "        #display(df1['result'])\n",
    "\n",
    "    traceroutes_hops = [] #all the hops for every traceroute\n",
    "    hops_results = [] #need a 2D list so that measurements are not mixed together ask for help in writing this.\n",
    "    hop_result2 = []\n",
    "    count = 0\n",
    "    count2 = 0\n",
    "    count3 = 0  \n",
    "    count4 = 0\n",
    "    count6 = 0\n",
    "    total = []  \n",
    "    ip_totals = []\n",
    "    ip_rtt_list = []\n",
    "    traceroutes_final = []\n",
    "    traceroutes_final2 = []\n",
    "    trace_avg_rtt = []\n",
    "    rtt_totals = 0\n",
    "\n",
    "    for trace in traceroutes['result']:\n",
    "        traceroutes_hops.append(pd.json_normalize(trace))\n",
    "\n",
    "        for hop in traceroutes_hops[count]['result']:\n",
    "            hops_results.append(pd.json_normalize(hop))\n",
    "            \n",
    "            #t = length(y)\n",
    "            #print(\"t:\", t)\n",
    "            #for z in hops_result[]\n",
    "            count2+=1\n",
    "        count+=1\n",
    "\n",
    "    #just displays list of avg rtt times in order of all ips\n",
    "    #RTT per hop   \n",
    "\n",
    "    for x in hops_results:\n",
    "        \n",
    "        if hasattr(x,'rtt'):\n",
    "  \n",
    "            rtt_totals = (x['rtt'][0] + x['rtt'][1] + x['rtt'][2])/3\n",
    "\n",
    "            hop_result2.append(rtt_totals)\n",
    "\n",
    "    #list of avg rtt times in order of all ips\n",
    "    #display(hop_result2)\n",
    "\n",
    "    #makes a list of ips and avg rtts together \n",
    "    \n",
    "    for x in hops_results: \n",
    "        if hasattr(x,'rtt'):\n",
    "            count3+=1\n",
    "\n",
    "    for x in hops_results:\n",
    "\n",
    "        if hasattr(x,'rtt'):\n",
    "                #ip_totals.append(x['from'][0])\n",
    "            rtt_totals = (x['rtt'][0] + x['rtt'][1] + x['rtt'][2])/3\n",
    "\n",
    "            count3+=1\n",
    "\n",
    "            ip_rtt_list.append({\"ip\":x['from'][0], \"rtt\":rtt_totals})\n",
    "\n",
    "        hop_result2.append(rtt_totals)\n",
    "    \n",
    "    #list of ips and avg rtts together\n",
    "    #display(ip_rtt_list)\n",
    "    df10 = pd.DataFrame(ip_rtt_list)\n",
    "    #display(df10)\n",
    "    traceroute_rtt = []\n",
    "    for x, row in df10.iterrows():\n",
    "        if isinstance(df10['rtt'], float) and df10['rtt']: \n",
    "            traceroute_rtt.append(df10['rtt'])\n",
    "    #display(traceroute_rtt)\n",
    "    \n",
    "    #print(just_rtt)\n",
    "rtt_data = np.array(traceroute_rtt)\n",
    "count, bins_count = np.histogram(rtt_data, bins=300)\n",
    "pdf = count / sum(count)\n",
    "\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "    #plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "plt.plot(bins_count[1:], cdf, label=\"Traceroute RTT CDF\")\n",
    "#plt.axis([0,140,0,1.0])\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Traceroute RTT')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('RTT(in milliseconds)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "    \n",
    "    #creates datafram of traceroute with hops within, with only ip and avg rtt for each hop\n",
    "    #this list contains 2 extra hops that need to be removed\n",
    "    \n",
    "    \n",
    "    #for trace in traceroutes['result']:\n",
    "    #   traceroutes_final.append(pd.json_normalize(trace))\n",
    "        \n",
    "        #track overall traceroutes\n",
    "    #    count5 = 0\n",
    "    #   for hop in traceroutes_final[count4]['result']:\n",
    "            \n",
    "            #temp normalization so that the attr can be detected in the condition\n",
    "     #       temp_hop = pd.json_normalize(hop[count5])\n",
    "            \n",
    "      #      if hasattr(temp_hop,'rtt'):\n",
    "                #print('yes')\n",
    "\n",
    "      #          hop[count5] = ip_rtt_list[count6]\n",
    "                \n",
    "                #display(hop[count5])\n",
    "                #track each hop overall\n",
    "            \n",
    "     #           count6+=1\n",
    "                #display(hop[count5])\n",
    "                #traceroutes_final[count4]['result']\n",
    "            \n",
    "            #fix off by one erro\n",
    "     #       if count6 < 1:\n",
    "                #track each hop in loop\n",
    "     #           count5+=1\n",
    "        #track each traceroute\n",
    "      #  count4+=1\n",
    "        \n",
    "        \n",
    "    #displays datafram of traceroute with hops within, with only ip and rtt for each hop\n",
    "    \n",
    "    #display(traceroutes_final[0]['result'])\n",
    "    \n",
    "    #count, bins_count = np.histogram(data, bins=25)\n",
    "    \n",
    "\n",
    "    #for y in traceroutes_hops[1]['result']:\n",
    "        #count2+=1\n",
    "        #hops_result[1][].append(pd.json_normalize(y))\n",
    "        #display(traceroutes_hops)\n",
    "\n",
    "        #print(type(hops_results[count2]['rtt'][0]))\n",
    "\n",
    "        #display(hop_result2)\n",
    "\n",
    "        #display(pd.json_normalize(traceroutes['result']))\n",
    "\n",
    "        #for y in hops['results']:\n",
    "         #       hop_result.append(pd.json_normalize(y))\n",
    "            #display(hops)\n",
    "            #for y in hops[]\n",
    "            #display(df1['result'][x])\n",
    "            #df2[x] = pd.json_normalize(df1['result'][x])\n",
    "            #display(df2)\n",
    "\n",
    "        #hops = pd.Dataframe(traceroute['result'][1], columns = [])\n",
    "\n",
    "    #    just_rtt = []\n",
    "\n",
    "\n",
    "    #    for x, row in df1.iterrows():\n",
    "            #for each row\n",
    "    #        df1['result'][x] = pd.json_normalize(df1['result'][x])\n",
    "     #       display(df1['result'][x])\n",
    "\n",
    "            #PROBLEMS START HERE vv\n",
    "      #      for hop in df1['result'][x]:\n",
    "                #for each hop\n",
    "       #         df1['result'][x][hop] = pd.json_normalize(df1['result'][x][hop])\n",
    "       #         display(df1['result'][hop]['result'])\n",
    "\n",
    "        #        for r in df1['result'][x][hop]:\n",
    "                    #for hop result (collective)\n",
    "         #           df1['result'][x][hop][r] = pd.json_normalize(df1['result'][x][hop][r])\n",
    "\n",
    "          #          for y, row in df1['result'][x][hop][r].iterrows():\n",
    "           #             #for each hop result (individual)\n",
    "            #            df1['result'][x][hop][r][y] = pd.json_normalize(df1['result'][x][hop][r][y])\n",
    "\n",
    "             #           for z in df1['result'][x][hop][r][y]:\n",
    "                            #for each rtt\n",
    "              #              df1['result'][x][hop][r][y][z] = pd.json_normalize(df1['result'][x][hop][r][y][z])\n",
    "                            #append rtt to a list of rtts\n",
    "               #             just_rtt.append(df1['result'][x][hop][r][y][z])\n",
    "                            #display(df1['result'][x][hop][r][y][z])\n",
    "\n",
    "\n",
    "    #data = np.array(just_rtt)\n",
    "\n",
    "\n",
    "    #count, bins_count = np.histogram(data, bins=25)\n",
    "    #pdf = count / sum(count)\n",
    "\n",
    "    #cdf = np.cumsum(pdf)\n",
    "\n",
    "\n",
    "    #plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "    #plt.plot(bins_count[1:], cdf, label=\"CDF\")\n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traceroute RTT CDF (LEO VERSION)\n",
    "#does not work\n",
    "\n",
    "result = jc.parse('traceroute', 'traceTest.txt')\n",
    "\n",
    "traceroutes = pd.json_normalize(result)\n",
    "        #prototype path to an individual rtt\n",
    "    #    display(df1)\n",
    "    #    display(df1['result'][1][1]['result'][1]['rtt'])\n",
    "    #   df2 = df1['result'][1] #traceroute level\n",
    "    #    df2 = pd.json_normalize(df2) #hops level\n",
    "    #    df3 = df2['result'][1]\n",
    "    #    df3 = pd.json_normalize(df3) #1 hop level\n",
    "        #df2['rtt']\n",
    "    #    display(df3['rtt'])\n",
    "        #display(df1['result'])\n",
    "\n",
    "traceroutes_hops = [] #all the hops for every traceroute\n",
    "hops_results = [] #need a 2D list so that measurements are not mixed together ask for help in writing this.\n",
    "hop_result2 = []\n",
    "count = 0\n",
    "count2 = 0\n",
    "count3 = 0  \n",
    "count4 = 0\n",
    "count6 = 0\n",
    "total = []  \n",
    "ip_totals = []\n",
    "ip_rtt_list = []\n",
    "traceroutes_final = []\n",
    "traceroutes_final2 = []\n",
    "trace_avg_rtt = []\n",
    "rtt_totals = 0\n",
    "\n",
    "for trace in traceroutes['result']:\n",
    "    traceroutes_hops.append(pd.json_normalize(trace))\n",
    "\n",
    "    for hop in traceroutes_hops[count]['result']:\n",
    "        hops_results.append(pd.json_normalize(hop))\n",
    "        \n",
    "        #t = length(y)\n",
    "        #print(\"t:\", t)\n",
    "        #for z in hops_result[]\n",
    "        count2+=1\n",
    "    count+=1\n",
    "\n",
    "#just displays list of avg rtt times in order of all ips\n",
    "#RTT per hop   \n",
    "\n",
    "for x in hops_results:\n",
    "    \n",
    "    if hasattr(x,'rtt'):\n",
    "\n",
    "        rtt_totals = (x['rtt'][0] + x['rtt'][1] + x['rtt'][2])/3\n",
    "\n",
    "        hop_result2.append(rtt_totals)\n",
    "\n",
    "#list of avg rtt times in order of all ips\n",
    "#display(hop_result2)\n",
    "\n",
    "#makes a list of ips and avg rtts together \n",
    "\n",
    "for x in hops_results: \n",
    "    if hasattr(x,'rtt'):\n",
    "        count3+=1\n",
    "\n",
    "for x in hops_results:\n",
    "\n",
    "    if hasattr(x,'rtt'):\n",
    "            #ip_totals.append(x['from'][0])\n",
    "        rtt_totals = (x['rtt'][0] + x['rtt'][1] + x['rtt'][2])/3\n",
    "\n",
    "        count3+=1\n",
    "\n",
    "        ip_rtt_list.append({\"ip\":x['from'][0], \"rtt\":rtt_totals})\n",
    "\n",
    "    hop_result2.append(rtt_totals)\n",
    "\n",
    "#list of ips and avg rtts together\n",
    "#display(ip_rtt_list)\n",
    "df10 = pd.DataFrame(ip_rtt_list)\n",
    "#display(df10)\n",
    "traceroute_rtt = []\n",
    "for x, row in df10.iterrows():\n",
    "    if isinstance(df10['rtt'], float) and df10['rtt']: \n",
    "        traceroute_rtt.append(df10['rtt'])\n",
    "#display(traceroute_rtt)\n",
    "\n",
    "#print(just_rtt)\n",
    "rtt_data = np.array(traceroute_rtt)\n",
    "count, bins_count = np.histogram(rtt_data, bins=300)\n",
    "pdf = count / sum(count)\n",
    "\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "    #plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "plt.plot(bins_count[1:], cdf, label=\"Traceroute RTT CDF\")\n",
    "#plt.axis([0,140,0,1.0])\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Traceroute RTT')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('RTT(in milliseconds)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82315772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FIX THIS GRAPH TO START AT ZERO\n",
    "\n",
    "#Traceroute Hops CDF (RIPE ATLAS)\n",
    "kwargs = {\n",
    "    \"msm_id\": 38384555\n",
    "}\n",
    "\n",
    "is_success, results = AtlasResultsRequest(**kwargs).create()\n",
    "\n",
    "if is_success:\n",
    "    #print the json string\n",
    "    #print(results)\n",
    "\n",
    "    #CREATE A DATAFRAME WITH THE ENTIRETY OF THE MEASUREMENT RESULTS\n",
    "    df1 = pd.json_normalize(results)\n",
    "\n",
    "    #CREATE hops VARIABLE AND INITIALIZE TO ZERO\n",
    "    hops = 0\n",
    "\n",
    "    #CREATE EMPTY LIST hops_per_run\n",
    "    hops_per_run = []\n",
    "    #display(df1)\n",
    "    \n",
    "    #FOR EACH ROW IN DF1\n",
    "    for x, row in df1.iterrows():\n",
    "        \n",
    "        #NORMALIZE THE RESULTS\n",
    "        df1['result'][x] = pd.json_normalize(df1['result'][x])\n",
    "\n",
    "        #FOR EACH HOP IN THE ROW\n",
    "        for hop, row in df1['result'][x].iterrows():\n",
    "\n",
    "            #INCREMENT hops\n",
    "            hops = hops + 1\n",
    "            #has attribute\n",
    "            \n",
    "        #APPEND hops TO hops_per_run, hops IS EQUAL TO THE NUMBER OF HOPS IN A SINGLE ROW\n",
    "        hops_per_run.append(hops)\n",
    "    \n",
    "        #SET hops TO ZERO SO THAT EACH LOOP WILL PRODUCE THE CORRECT NUMBER OF HOPS IN A ROW\n",
    "        hops = 0\n",
    "    \n",
    "    #print(hops_per_run)\n",
    "\n",
    "#SET DATA TO hops_per_run     \n",
    "data = np.array(hops_per_run)\n",
    "\n",
    "#CREATE HISTOGRAM\n",
    "count, bins_count = np.histogram(data, bins=300)\n",
    "\n",
    "#CALCULATE PDF\n",
    "pdf = count / sum(count)\n",
    "\n",
    "#CALCULATE CDF\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "\n",
    "#plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n",
    "\n",
    "#PLOT CDF\n",
    "plt.plot(bins_count[1:], cdf, label=\"Traceroute Hops CDF\")\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Traceroute Hops')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('Hops')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "#ALTHOUGH BINS=300 IN THIS CELL, THE GRAPH WILL NEVER START AT 0 PERCENT DUE TO THE DATA IT CONTAINS\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traceroute Hops BAR GRAPH (RIPE ATLAS)\n",
    "kwargs = {\n",
    "    \"msm_id\": 38384555\n",
    "}\n",
    "\n",
    "is_success, results = AtlasResultsRequest(**kwargs).create()\n",
    "\n",
    "if is_success:\n",
    "    #print the json string\n",
    "    #print(results)\n",
    "\n",
    "    #CREATE A DATAFRAME WITH THE ENTIRETY OF THE MEASUREMENT RESULTS\n",
    "    df1 = pd.json_normalize(results)\n",
    "\n",
    "    #CREATE hops VARIABLE AND INITIALIZE TO ZERO\n",
    "    hops = 0\n",
    "\n",
    "    #CREATE EMPTY LIST hops_per_run\n",
    "    hops_per_run = []\n",
    "    #display(df1)\n",
    "    \n",
    "    #FOR EACH ROW IN DF1\n",
    "    for x, row in df1.iterrows():\n",
    "        \n",
    "        #NORMALIZE THE RESULTS\n",
    "        df1['result'][x] = pd.json_normalize(df1['result'][x])\n",
    "\n",
    "        #FOR EACH HOP IN THE ROW\n",
    "        for hop, row in df1['result'][x].iterrows():\n",
    "\n",
    "            #INCREMENT hops\n",
    "            hops = hops + 1\n",
    "            #has attribute\n",
    "            \n",
    "        #APPEND hops TO hops_per_run, hops IS EQUAL TO THE NUMBER OF HOPS IN A SINGLE ROW\n",
    "        hops_per_run.append(hops)\n",
    "    \n",
    "        #SET hops TO ZERO SO THAT EACH LOOP WILL PRODUCE THE CORRECT NUMBER OF HOPS IN A ROW\n",
    "        hops = 0\n",
    "    \n",
    "#CREATE count_num TO KEEP TRACK OF NUMBER OCCURENCES\n",
    "count_num = 0\n",
    "\n",
    "#CREATE unique_num LIST\n",
    "unique_num = []\n",
    "\n",
    "#CREATE num_occurence LIST\n",
    "num_occurence = []\n",
    "\n",
    "#FOR EACH item IN hops_per_run\n",
    "for item in hops_per_run:\n",
    "    #IF THE ITEM IS NOT IN THE unique_num LIST, ADD IT\n",
    "    if item not in unique_num:\n",
    "            unique_num.append(item)\n",
    "#WE NOW HAVE A LIST OF ALL THE UNIQUE NUMBERS OF HOPS\n",
    "\n",
    "#print(unique_num)\n",
    "\n",
    "#FOR EACH i IN unique_num\n",
    "for i in unique_num:\n",
    "    #print(i)\n",
    "    #FOR EACH item IN hops_per_run\n",
    "    for item in hops_per_run:\n",
    "        #IF THE item IS EQUAL TO i THEN INCREMENT count_num\n",
    "        if item == i:\n",
    "            count_num = count_num + 1\n",
    "    #APPEND count_num TO num_occurence\n",
    "    num_occurence.append(count_num)\n",
    "    #print(count_num)\n",
    "    #RESET count_num\n",
    "    count_num = 0\n",
    "#WE NOW HAVE A LIST OF THE NUMBER OF OCCURENCES OF EACH UNIQUE NUMBER OF HOPS\n",
    "\n",
    "#print(num_occurence)\n",
    "\n",
    "\n",
    "plt.bar(x = unique_num, height = num_occurence, width = 0.5)\n",
    "plt.title('Traceroute Hops')\n",
    "plt.ylabel('Number of Measurements')\n",
    "plt.xlabel('Hops')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traceroute RTT and Traceroute Hops (RIPE ATLAS)\n",
    "import math\n",
    "kwargs = {\n",
    "    \"msm_id\": 38384555\n",
    "}\n",
    "\n",
    "is_success, results = AtlasResultsRequest(**kwargs).create()\n",
    "\n",
    "if is_success:\n",
    "\n",
    "    #CREATE A DATAFRAME WITH THE ENTIRETY OF THE MEASUREMENT RESULTS\n",
    "    df1 = pd.json_normalize(results)\n",
    "\n",
    "    rtt_within_hop = 0              #where we will add the 0-3 rtt results for each individual hop\n",
    "    rtt_within_hop_count = 0        #to keep track of how many rtt results are in each hop\n",
    "    average_rtt = 0                 #for the average rtt within each hop\n",
    "    total_rtt_one_measurement = 0   #to add all of the hop averages to find overall rtt within one traceroute measurement\n",
    "\n",
    "    traceroutes_hops = []           #all the hops for every traceroute\n",
    "    hops_results = []               #need a 2D list so that measurements are not mixed together ask for help in writing this.\n",
    "    hop_result2 = []                #holds average rtts per hop\n",
    "    count = 0                       #count measurements\n",
    "    count2 = 0                      #count hops\n",
    "  \n",
    "\n",
    "    for trace in df1['result']:     #for each measurement\n",
    "        traceroutes_hops.append(pd.json_normalize(trace)) \n",
    "\n",
    "        for hop in traceroutes_hops[count]['result']:   #for each hop\n",
    "            hops_results.append(pd.json_normalize(hop))\n",
    "            \n",
    "            count2+=1\n",
    "        count+=1\n",
    "      \n",
    "\n",
    "    for x in hops_results:                                                     #for each hop\n",
    "\n",
    "        if hasattr(x,'rtt'):                                                #if the hop has an rtt column\n",
    "\n",
    "            if hasattr(x,'x') == False or (x['x'][0] == '*') == False:      #if it doesn't have an x column or if the x column is not equal to *\n",
    "                rtt_within_hop = rtt_within_hop + x['rtt'][0]               #add the rtt to the rtt_within_hop variable\n",
    "                rtt_within_hop_count = rtt_within_hop_count + 1             #increment count\n",
    "            if hasattr(x,'x') == False or (x['x'][1] == '*') == False:\n",
    "                rtt_within_hop = rtt_within_hop + x['rtt'][1]\n",
    "                rtt_within_hop_count = rtt_within_hop_count + 1\n",
    "            if hasattr(x,'x') == False or (x['x'][2] == '*') == False:\n",
    "                rtt_within_hop = rtt_within_hop + x['rtt'][2]\n",
    "                rtt_within_hop_count = rtt_within_hop_count + 1\n",
    "\n",
    "        if rtt_within_hop_count == 0:                                       #if the count is zero then set average_rtt to * (so that it is easy to find\n",
    "            average_rtt = '*'                                               #the measurements that did not complete later in the process and to avoid errors)\n",
    "        else:\n",
    "            average_rtt = rtt_within_hop / rtt_within_hop_count             #if count is not zero then calculate the rtt average\n",
    "\n",
    "        hop_result2.append(average_rtt)                                     #append the averages to a list hop_result2\n",
    "\n",
    "        rtt_within_hop = 0                                                  #reset rtt_within_hop, rtt_within_hop_count, and average_rtt to zero\n",
    "        rtt_within_hop_count = 0\n",
    "        average_rtt = 0\n",
    "\n",
    "\n",
    "\n",
    "    hops = 0                    #keeps track of hop number\n",
    "    hops_per_run = []           #list to hold the hop numbers\n",
    "    start = 0                   #needed for range\n",
    "    stop = 0                    #needed for range\n",
    "    total_rtt_all_measurements = []     #list to hold the total rtts for each measurement\n",
    "    count_m = 0                 #keeps track of how many measurements you have gone through (not really needed)\n",
    "    count_star = 0              #keeps track of stars encountered (not really needed)\n",
    "    \n",
    "\n",
    "    for x, row in df1.iterrows():                                           #for each row in df1\n",
    "        \n",
    "        df1['result'][x] = pd.json_normalize(df1['result'][x])              #normalize the results\n",
    "\n",
    "        for hop, row in df1['result'][x].iterrows():                        #for each hop in a single row\n",
    "\n",
    "            hops = hops + 1                                                 #increment hops\n",
    "            \n",
    "        hops_per_run.append(hops)                                           #append hops to hops_per_run, hops is equal to the number of hops in a single row (measurement)\n",
    "    \n",
    "        hops = 0                                                            #set hops to zero so that each loop will produce the correct number of hops per row\n",
    "    \n",
    "    \n",
    "    for i in hops_per_run:                                                  #for each number in hops_per_run\n",
    "        stop = stop + i                                                     #stop increments by i so that we can coordinate the range with the order of hop numbers in hops_per_run\n",
    "        for avg in range (start, stop):                                     #for each rtt in the range\n",
    "            if hop_result2[avg] == '*':                                     #if a star replaces any rtt within the range\n",
    "                count_star += 1                                             #increment count_star\n",
    "                total_rtt_one_measurement = '*'                             #the total_rtt_one measurement is set to * (we cannot include it in the set)\n",
    "                break                                                       #and the loop is broken for that range\n",
    "            total_rtt_one_measurement = total_rtt_one_measurement + hop_result2[avg]    #we add all of the rtts within range to calculate the total rtt for a single measurement\n",
    "        \n",
    "        total_rtt_all_measurements.append(total_rtt_one_measurement)        #add the totals to total_rtt_all_measurements\n",
    "        count_m += 1                                                        #increment count_m (because the rtt of one measurement of i hops has been calculated)\n",
    "        total_rtt_one_measurement = 0                                       #reset total_rtt_one_measurement to zero\n",
    "        start = stop                                                        #start = stop so that we can collect data accurately\n",
    "    \n",
    "\n",
    "    unique_num = []                         #this list will hold all of the unique hop counts\n",
    "    total_hop_occurence = 0                 #keeps track of hop count occurence\n",
    "    collective_rtt = 0                      #keeps track of collective rtt of a specific hop count\n",
    "    average_rtt_of_hop = 0                  #keeps track of average rtt of a measurement with i number of hops\n",
    "    all_averages = []                       #holds all of the rtt averages\n",
    "    finished_hop_num = []                   #holds the hop counts of measurements that finished\n",
    "    finished_hop_count = []                 #holds the occurence of measurements that finished\n",
    "    data_for_stddev = []                    #will hold the rtts temporarily to calculate standard deviation\n",
    "    stddev = 0\n",
    "    std_for_hop = []\n",
    "\n",
    "\n",
    "    for item in hops_per_run:                                               #for each item in hops_per_run\n",
    "        if item not in unique_num:                                          #if the item is not in unique_num, it is added\n",
    "                unique_num.append(item)\n",
    "\n",
    "    for item in unique_num:                                                 #for each item in unique_num\n",
    "        for i in range(0, len(hops_per_run)):                               #for each index within the length of hops_per_run\n",
    "            if hops_per_run[i] == item:                                     #if hops_per_run at that index is equal to the item in unique_num\n",
    "                if total_rtt_all_measurements[i] != '*':                    #if the rtt at index i of total_rtt_all_measurements is not a * (* means the measurement did not complete)\n",
    "                    total_hop_occurence += 1                                #increment total_hop_occurence\n",
    "                    collective_rtt += total_rtt_all_measurements[i]         #add the rtt to collective_rtt\n",
    "                    data_for_stddev.append(total_rtt_all_measurements[i])\n",
    "\n",
    "        if total_hop_occurence != 0:                                        #if total_hop_occurence is not zero\n",
    "            average_rtt_of_hop = collective_rtt / total_hop_occurence       #calculate the average rtt of hop count \"item\"\n",
    "            finished_hop_num.append(item)                                   #append hop count \"item\" to finished_hop_num\n",
    "            finished_hop_count.append(total_hop_occurence)                  #append the total_hop_occurence to finished_hop_count\n",
    "        else:\n",
    "            average_rtt_of_hop = '*'                                        #if total_hop_occurence is zero, the average rtt of the hop count \"item\" is set to *\n",
    "        if average_rtt_of_hop != '*':                                       #if the average_rtt_of_hop is not a * (measurements were completed), append to all_averages\n",
    "            all_averages.append(average_rtt_of_hop)\n",
    "        total_hop_occurence = 0                                             #reset total_hop_occurence and collective_rtt to zero\n",
    "        collective_rtt = 0\n",
    "\n",
    "        stddev = np.std(data_for_stddev)\n",
    "        if math.isnan(stddev) == False:\n",
    "            std_for_hop.append(stddev)\n",
    "        data_for_stddev.clear()\n",
    "\n",
    "    \n",
    "    # zip_object = zip(unique_num, all_averages)\n",
    "    # display(list(zip_object))\n",
    "    # zip_object = zip(finished_hop_num, finished_hop_count)\n",
    "    # display(list(zip_object))\n",
    "\n",
    "\n",
    "plt.bar(x = finished_hop_num, height = all_averages, width = 1, yerr = std_for_hop, align='center', alpha=0.5, capsize=10)\n",
    "plt.title('Traceroute RTT')\n",
    "plt.ylabel('Round Trip Time (milliseconds)')\n",
    "plt.xlabel('Hops')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.bar(x = finished_hop_num, height = finished_hop_count, width = 1)\n",
    "plt.title('Traceroute Hop Occurence')\n",
    "plt.ylabel('Number of Measurements')\n",
    "plt.xlabel('Hops')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#combine traceroute hops cell into this cell because we already have access to which measurements completed so we can add a count var within\n",
    "#the for loop to capture the occurences of completed measurements per hop count and append to a list then graph both inside of one cell :)\n",
    "\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traceroute Hops perfSONAR\n",
    "#files = ['136_10hr.json', '141_10hr.json', '192_10hr.json', '66_10hr.json', '206_10hr.json', '207_10hr.json', '209_10hr.json', '216_10hr.json', '67_10hr.json']\n",
    "files = ['136_10hr.json', '67_10hr.json', '206_10hr.json']\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "\n",
    "    data_points = 0\n",
    "    hops = 0\n",
    "    total_hop_occurence = 0\n",
    "    hop_rtt = 0 \n",
    "    total_rtt = 0\n",
    "    average_rtt = 0\n",
    "    stddev = 0\n",
    "    collective_rtt = 0\n",
    "    ttl = 0\n",
    "    dest = ''\n",
    "\n",
    "\n",
    "    total_hops = []\n",
    "    unique_num = []\n",
    "    finished_hop_num = []\n",
    "    finished_hop_count = []\n",
    "    total_averages = []\n",
    "    total_rtts = []\n",
    "    std_for_hop = []\n",
    "\n",
    "\n",
    "    for i in data:\n",
    "        data_points = data_points + 1\n",
    "        for item in data[data_points - 1]['val']:\n",
    "            ttl += 1                                                    #keep track of attempted hops\n",
    "            if 'rtt' in item:                                           #only sums the completed hops\n",
    "                hops = hops + 1\n",
    "                hop_rtt = item['rtt']\n",
    "                total_rtt += hop_rtt\n",
    "\n",
    "        if 'rtt' not in i['val'][ttl-1]:                                #check if trace actually finished\n",
    "            hops = '*'                                                  #if no rtt, trace didn't finish, so set hops to *\n",
    "        else:\n",
    "            dest = i['val'][ttl-1]['ip']                                #store destination to use in graph label\n",
    "\n",
    "        if hops != '*' :\n",
    "            total_hops.append(hops)\n",
    "            total_rtts.append(total_rtt)\n",
    "            average_rtt = total_rtt/hops\n",
    "\n",
    "        hops = 0\n",
    "        total_rtt = 0\n",
    "        average_rtt = 0\n",
    "        ttl = 0\n",
    "\n",
    "    for item in total_hops:                                               #for each item in hops_per_run\n",
    "        if item not in unique_num:                                          #if the item is not in unique_num, it is added\n",
    "                unique_num.append(item)\n",
    "\n",
    "    for item in unique_num:                                                 #for each item in unique_num\n",
    "            for i in range(0, len(total_hops)):                               #for each index within the length of hops_per_run\n",
    "                if total_hops[i] == item:                                     #if hops_per_run at that index is equal to the item in unique_num\n",
    "                    #if total_rtt_all_measurements[i] != '*':                    #if the rtt at index i of total_rtt_all_measurements is not a * (* means the measurement did not complete)\n",
    "                    total_hop_occurence += 1                               #increment total_hop_occurence\n",
    "                    collective_rtt += total_rtts[i]         #add the rtt to collective_rtt\n",
    "                        #data_for_stddev.append(total_rtt_all_measurements[i])\n",
    "\n",
    "            if total_hop_occurence != 0:                                        #if total_hop_occurence is not zero\n",
    "                average_rtt_of_hop = collective_rtt / total_hop_occurence       #calculate the average rtt of hop count \"item\"\n",
    "                finished_hop_num.append(item)                                   #append hop count \"item\" to finished_hop_num\n",
    "                finished_hop_count.append(total_hop_occurence)                  #append the total_hop_occurence to finished_hop_count\n",
    "            #else:\n",
    "                #average_rtt_of_hop = '*'                                        #if total_hop_occurence is zero, the average rtt of the hop count \"item\" is set to *\n",
    "            #if average_rtt_of_hop != '*':                                       #if the average_rtt_of_hop is not a * (measurements were completed), append to all_averages\n",
    "            total_averages.append(average_rtt_of_hop)\n",
    "            total_hop_occurence = 0                                             #reset total_hop_occurence and collective_rtt to zero\n",
    "            collective_rtt = 0\n",
    "\n",
    "            stddev = np.std(total_rtts)\n",
    "            if math.isnan(stddev) == False:\n",
    "                std_for_hop.append(stddev)\n",
    "\n",
    "\n",
    "\n",
    "    plt.bar(x = finished_hop_num, height = total_averages, width = 0.5, yerr = std_for_hop, align='center', alpha=0.75, capsize=10)\n",
    "\n",
    "plt.title('Traceroute RTT ')\n",
    "plt.ylabel('Round Trip Time (milliseconds)')\n",
    "plt.xlabel('Hops')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "\n",
    "    data_points = 0\n",
    "    hops = 0\n",
    "    total_hop_occurence = 0\n",
    "    hop_rtt = 0 \n",
    "    total_rtt = 0\n",
    "    average_rtt = 0\n",
    "    stddev = 0\n",
    "    collective_rtt = 0\n",
    "    ttl = 0\n",
    "    dest = ''\n",
    "\n",
    "\n",
    "    total_hops = []\n",
    "    unique_num = []\n",
    "    finished_hop_num = []\n",
    "    finished_hop_count = []\n",
    "    total_averages = []\n",
    "    total_rtts = []\n",
    "    std_for_hop = []\n",
    "\n",
    "\n",
    "    for i in data:\n",
    "        data_points = data_points + 1\n",
    "        for item in data[data_points - 1]['val']:\n",
    "            ttl += 1                                                    #keep track of attempted hops\n",
    "            if 'rtt' in item:                                           #only sums the completed hops\n",
    "                hops = hops + 1\n",
    "                hop_rtt = item['rtt']\n",
    "                total_rtt += hop_rtt\n",
    "\n",
    "        if 'rtt' not in i['val'][ttl-1]:                                #check if trace actually finished\n",
    "            hops = '*'                                                  #if no rtt, trace didn't finish, so set hops to *\n",
    "        else:\n",
    "            dest = i['val'][ttl-1]['ip']                                #store destination to use in graph label\n",
    "\n",
    "        if hops != '*' :\n",
    "            total_hops.append(hops)\n",
    "            total_rtts.append(total_rtt)\n",
    "            average_rtt = total_rtt/hops\n",
    "\n",
    "        hops = 0\n",
    "        total_rtt = 0\n",
    "        average_rtt = 0\n",
    "        ttl = 0\n",
    "\n",
    "    for item in total_hops:                                               #for each item in hops_per_run\n",
    "        if item not in unique_num:                                          #if the item is not in unique_num, it is added\n",
    "                unique_num.append(item)\n",
    "\n",
    "    for item in unique_num:                                                 #for each item in unique_num\n",
    "            for i in range(0, len(total_hops)):                               #for each index within the length of hops_per_run\n",
    "                if total_hops[i] == item:                                     #if hops_per_run at that index is equal to the item in unique_num\n",
    "                    #if total_rtt_all_measurements[i] != '*':                    #if the rtt at index i of total_rtt_all_measurements is not a * (* means the measurement did not complete)\n",
    "                    total_hop_occurence += 1                               #increment total_hop_occurence\n",
    "                    collective_rtt += total_rtts[i]         #add the rtt to collective_rtt\n",
    "                        #data_for_stddev.append(total_rtt_all_measurements[i])\n",
    "\n",
    "            if total_hop_occurence != 0:                                        #if total_hop_occurence is not zero\n",
    "                average_rtt_of_hop = collective_rtt / total_hop_occurence       #calculate the average rtt of hop count \"item\"\n",
    "                finished_hop_num.append(item)                                   #append hop count \"item\" to finished_hop_num\n",
    "                finished_hop_count.append(total_hop_occurence)                  #append the total_hop_occurence to finished_hop_count\n",
    "            #else:\n",
    "                #average_rtt_of_hop = '*'                                        #if total_hop_occurence is zero, the average rtt of the hop count \"item\" is set to *\n",
    "            #if average_rtt_of_hop != '*':                                       #if the average_rtt_of_hop is not a * (measurements were completed), append to all_averages\n",
    "            total_averages.append(average_rtt_of_hop)\n",
    "            total_hop_occurence = 0                                             #reset total_hop_occurence and collective_rtt to zero\n",
    "            collective_rtt = 0\n",
    "\n",
    "            stddev = np.std(total_rtts)\n",
    "            if math.isnan(stddev) == False:\n",
    "                std_for_hop.append(stddev)\n",
    "\n",
    "    plt.scatter(x = finished_hop_num, y = finished_hop_count, s = 50)\n",
    "plt.title('Traceroute Hop Occurence ')\n",
    "plt.ylabel('Number of Measurements')\n",
    "plt.xlabel('Hops')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#change to clusters/ scatterplot\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traceroute Hops CDF (perfSONAR)\n",
    "#files = ['136_10hr.json', '141_10hr.json', '192_10hr.json', '66_10hr.json', '206_10hr.json', '207_10hr.json', '209_10hr.json', '216_10hr.json', '67_10hr.json']\n",
    "\n",
    "files = ['136_10hr.json', '67_10hr.json', '206_10hr.json']\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "\n",
    "    data_points = 0\n",
    "    hops = 0\n",
    "    ttl = 0\n",
    "    dest = ''\n",
    "\n",
    "    total_hops = []\n",
    "\n",
    "\n",
    "    for i in data:\n",
    "        data_points = data_points + 1\n",
    "        for item in data[data_points - 1]['val']:\n",
    "            ttl += 1                                                    #keep track of attempted hops\n",
    "            if 'rtt' in item:                                           #only sums the completed hops\n",
    "                hops = hops + 1\n",
    "\n",
    "        if 'rtt' not in i['val'][ttl-1]:                                #check if trace actually finished\n",
    "            hops = '*'                                                  #if no rtt, trace didn't finish, so set hops to *\n",
    "        else:\n",
    "            dest = i['val'][ttl-1]['ip']                                #store destination to use in graph label\n",
    "\n",
    "        if hops != '*' :\n",
    "            total_hops.append(hops)\n",
    "\n",
    "        hops = 0\n",
    "        ttl = 0\n",
    "\n",
    "    #SET DATA TO hops_per_run     \n",
    "    data = np.array(total_hops)\n",
    "\n",
    "    #CREATE HISTOGRAM\n",
    "    count, bins_count = np.histogram(data, bins=300)\n",
    "\n",
    "    #CALCULATE PDF\n",
    "    pdf = count / sum(count)\n",
    "\n",
    "    #CALCULATE CDF\n",
    "    cdf = np.cumsum(pdf)\n",
    "\n",
    "\n",
    "    #PLOT CDF\n",
    "    plt.plot(bins_count[1:], cdf, label=dest)\n",
    "\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Traceroute Hops CDF')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xlabel('Hops')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "#ALTHOUGH BINS=300 IN THIS CELL, THE GRAPH WILL NEVER START AT 0 PERCENT DUE TO THE DATA IT CONTAINS\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
